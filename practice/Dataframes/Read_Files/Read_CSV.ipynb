{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec77214e-0456-4a95-a1e5-13c57e8ad34b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Import CSV\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d73f583-3afd-42a2-9641-165e6c61caff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+------------+------+\n|_c0|    _c1|_c2|         _c3|   _c4|\n+---+-------+---+------------+------+\n| id|   name|age|        city|salary|\n|  1|  Alice| 28|    New York| 70000|\n|  2|    Bob| 34| Los Angeles| 85000|\n|  3|Charlie| 25|     Chicago| 62000|\n|  4|  David| 45|     Houston| 95000|\n|  5|    Eva| 30|     Phoenix| 72000|\n|  6|  Frank| 38|Philadelphia| 88000|\n|  7|  Grace| 27| San Antonio| 64000|\n|  8| Hannah| 32|   San Diego| 79000|\n|  9|    Ian| 29|      Dallas| 73000|\n| 10|  Julia| 41|    San Jose| 91000|\n+---+-------+---+------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df_csv= spark.read.csv('/Volumes/workspace/practice/my_volume/csv_file.csv')\n",
    "df_csv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e76b6ed0-163d-468f-b59c-92088b35871f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+------------+------+\n| id|   name|age|        city|salary|\n+---+-------+---+------------+------+\n|  1|  Alice| 28|    New York| 70000|\n|  2|    Bob| 34| Los Angeles| 85000|\n|  3|Charlie| 25|     Chicago| 62000|\n|  4|  David| 45|     Houston| 95000|\n|  5|    Eva| 30|     Phoenix| 72000|\n|  6|  Frank| 38|Philadelphia| 88000|\n|  7|  Grace| 27| San Antonio| 64000|\n|  8| Hannah| 32|   San Diego| 79000|\n|  9|    Ian| 29|      Dallas| 73000|\n| 10|  Julia| 41|    San Jose| 91000|\n+---+-------+---+------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df_csv= spark.read.csv('/Volumes/workspace/practice/my_volume/csv_file.csv',inferSchema=True,header=True,sep=',')\n",
    "df_csv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9723350c-5eb1-4967-ba01-98e116bd536f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- age: integer (nullable = true)\n |-- city: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df_csv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "248bb45f-e67d-412b-8aab-f56c3ceddaaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_csv.write.mode(\"overwrite\").saveAsTable(\"workspace.practice.csv_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d40d3c66-ad79-4933-84f5-e63e59a84f23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+------------+------+\n| id|   name|age|        city|salary|\n+---+-------+---+------------+------+\n|  1|  Alice| 28|    New York| 70000|\n|  2|    Bob| 34| Los Angeles| 85000|\n|  3|Charlie| 25|     Chicago| 62000|\n|  4|  David| 45|     Houston| 95000|\n|  5|    Eva| 30|     Phoenix| 72000|\n|  6|  Frank| 38|Philadelphia| 88000|\n|  7|  Grace| 27| San Antonio| 64000|\n|  8| Hannah| 32|   San Diego| 79000|\n|  9|    Ian| 29|      Dallas| 73000|\n| 10|  Julia| 41|    San Jose| 91000|\n+---+-------+---+------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df_csv= spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").option(\"delimiter\",\",\").csv('/Volumes/workspace/practice/my_volume/csv_file.csv')\n",
    "df_csv.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e4fe258-b266-4506-9964-ef337552f150",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+\n| id|   name|price|\n+---+-------+-----+\n|  1|  Alice| 28.0|\n|  2|    Bob| 34.0|\n|  3|Charlie| 25.0|\n|  4|  David| 45.0|\n|  5|    Eva| 30.0|\n|  6|  Frank| 38.0|\n|  7|  Grace| 27.0|\n|  8| Hannah| 32.0|\n|  9|    Ian| 29.0|\n| 10|  Julia| 41.0|\n+---+-------+-----+\n\nroot\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- price: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "\n",
    "# Define schema explicitly\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"price\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# Read CSV with delimiter specified\n",
    "df_csv = spark.read.csv(\n",
    "    '/Volumes/workspace/practice/my_volume/csv_file.csv',\n",
    "    schema=schema,\n",
    "    header=True,\n",
    "    sep=\",\"   # Explicitly mention delimiter\n",
    ")\n",
    "\n",
    "df_csv.show()\n",
    "df_csv.printSchema()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Read_CSV",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}